# docker-compose.yml

version: '3.8'

services:
  # Service 1: The MLflow Tracking Server
  mlflow-server:
    build:
      context: .
      dockerfile: mlflow.Dockerfile
    ports:
      # Expose the MLflow UI on your machine at port 5002
      - "5002:5000"
    volumes:
      # This makes the MLflow data (your models) persistent across restarts
      - ./mlruns:/mlruns
    networks:
      - ml-network

  # Service 2: The Flask API
  api:
    # This is the crucial line. It tells docker-compose to use your
    # official image from Docker Hub for this service during deployment.
    image: apurbaghosh363/iris-mlops-api:latest
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8002:8000"
    depends_on:
      - mlflow-server
    volumes:
      # This makes the API's logs persistent
      - ./logs:/app/logs
    networks:
      - ml-network

  # Service 3: prometheus for monitoring
  # This service will scrape metrics from the API and make them available for Grafana
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      # Mount the configuration file we just created into the container
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
    networks:
      - ml-network

  # Service 4: Grafana for visualization
  # This service provides a web interface for visualizing metrics collected by Prometheus
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
    networks:
      - ml-network
    volumes:
      # This makes Grafana's data persistent
      - ./grafana-data:/var/lib/grafana
# Define the private network for the containers to communicate
networks:
  ml-network:
    driver: bridge
